{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sta/pltips\n",
      "sta/cartesian_coordinates\n",
      "sta/centers_of_mass\n",
      "sta/force_systems\n",
      "sta/frames_and_machines\n",
      "sta/free_body_diagrams\n",
      "sta/friction\n",
      "sta/hydrostatic_fluid_pressure\n",
      "sta/introduction\n",
      "sta/moment_of_inertia\n",
      "sta/moments\n",
      "sta/reaction_forces\n",
      "sta/shear_moment_diagrams\n",
      "sta/trusses\n",
      "sta/vectors_scalars\n",
      "sta/virtual_work\n",
      "sol/axial_loading\n",
      "sol/beam_deflection\n",
      "sol/buckling\n",
      "sol/combined_loading\n",
      "sol/failure_theories\n",
      "sol/pressure_vessels\n",
      "sol/shear_moment_diagrams\n",
      "sol/bending\n",
      "sol/stress\n",
      "sol/stress_transformation\n",
      "sol/torsion\n",
      "sol/transverse_shear\n",
      "sol/strain\n",
      "sol/material_properties\n",
      "dyn/vectors\n",
      "dyn/work_and_energy\n",
      "dyn/contact_and_rolling\n",
      "dyn/rigid_body_kinetics\n",
      "dyn/particle_kinematics\n",
      "dyn/particle_kinetics\n",
      "dyn/rigid_body_kinematics\n",
      "dyn/vector_calculus\n",
      "thermodynamics/complex_problems\n",
      "thermodynamics/cycles\n",
      "thermodynamics/entropy\n",
      "thermodynamics/heat_and_work\n",
      "thermodynamics/mass_and_energy_balances\n",
      "thermodynamics/substances\n",
      "thermodynamics/thermodynamic_devices\n",
      "thermodynamics/thermodynamic_systems\n",
      "md/Cams\n",
      "md/Instant_Centers\n",
      "md/Dynamic_Force_Analysis\n",
      "md/Graphical_Linkage_Synthesis\n",
      "md/Position_Velocity_Acceleration\n",
      "md/Virtual_Work\n",
      "md/Balancing\n",
      "mf/Failure_Theories\n",
      "mf/Stress_Concentrations\n",
      "mf/Threaded_Components\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "\n",
    "pwd = os.path.dirname(os.getcwd())\n",
    "\n",
    "searchable_pages = []\n",
    "\n",
    "for dir in ['sta', 'sol', 'dyn', 'thermodynamics', 'md', 'mf']:\n",
    "    dir_path = os.path.join(pwd, \"src/pages\", dir)\n",
    "    for page in os.listdir(dir_path):\n",
    "        searchable_pages.append(os.path.join(dir, page.replace(\".astro\", '')))\n",
    "\n",
    "page_text = []\n",
    "\n",
    "for page in searchable_pages:\n",
    "    print(page)\n",
    "    url = f\"http://localhost:4321/{page}\"\n",
    "    html = requests.get(url).text\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "    # kill all script and style elements\n",
    "    for script in soup([\"script\", \"style\", \"nav\", 'header', 'footer']):\n",
    "        script.extract()    # rip it out\n",
    "\n",
    "    try:\n",
    "        soup.find(\"div\", attrs={\"id\": \"nav_container\"}).extract()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        soup.find(\"h1\", attrs={\"id\": \"page_title\"}).extract()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        soup.find(\"div\", attrs={\"id\": \"title_bar\"}).extract()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # get text\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # break into lines and remove leading and trailing space on each\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    # break multi-headlines into a line each\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    # drop blank lines\n",
    "    text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "    banned_strings = [\n",
    "        \"Derivation +\",\n",
    "        \"Solution +\",\n",
    "        \"All courses Statics Dynamics Solid Mechanics \",\n",
    "        \"Scroll back to top\"\n",
    "    ]\n",
    "\n",
    "    for b in banned_strings:    \n",
    "        text = text.replace(b, \"\")\n",
    "\n",
    "    page_text.append({\"title\": page.split(\"/\")[1].replace(\"_\", \" \").capitalize(),\"text\": text, 'link': \"/\" + page, 'course': page.split('/')[0]})\n",
    "\n",
    "json.dump(page_text, open(\"../src/search.json\", \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
